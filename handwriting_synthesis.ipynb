{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwriting-synthesis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anibohara2000/hand-syn/blob/master/handwriting_synthesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "00GF4u5aqGyg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdpWw59-So_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.layers import Input, LSTM, Bidirectional, Dense, Embedding\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vwELnIE8s_mC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "letters = np.load('letters.npy', allow_pickle=True).item()\n",
        "def coord_to_offset(d):\n",
        "    for key in d:\n",
        "        newl = []\n",
        "        for l in d[key]:\n",
        "            for i in range(1, len(l)):\n",
        "                l[i] = [l[i][0] - l[i - 1][0], l[i][1] - l[i - 1][1], l[i][2]]\n",
        "            l[0] = [0, 0, l[0][2]]\n",
        "            newl.append(l)\n",
        "        d[key] = newl\n",
        "    return d\n",
        "letters = coord_to_offset(letters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X2MCWJ-msvhj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Number of words to consider as features\n",
        "# max_features = 10000\n",
        "# Cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 200\n",
        "\n",
        "# # Load IMDB sentiment data. Skip top most common words.\n",
        "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features,\n",
        "#                                                       skip_top=10)\n",
        "\n",
        "# # Reverse sequences\n",
        "# x_train = [x[::-1] for x in x_train]\n",
        "# x_test = [x[::-1] for x in x_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoSC8dRRV8yg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "for l in letters:\n",
        "    letters[l] = sequence.pad_sequences(letters[l], maxlen=maxlen, padding='post')\n",
        "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xnEmLVQk5wK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "for key in letters:\n",
        "    for l in letters[key]:\n",
        "        x.append(key)\n",
        "        y.append(l)\n",
        "x_train = np.zeros((len(x), maxlen, 52))\n",
        "y_train = np.zeros((len(y), maxlen, 3))\n",
        "for i in range(len(x)):\n",
        "    y_train[i, :, :] = y[i]\n",
        "    l = [0.0 for k in range(52)]\n",
        "    if(ord(x[i])-65 <= 25):\n",
        "      l[ord(x[i])-65] = 1.0\n",
        "    else:\n",
        "      l[26+ord(x[i])-97] = 1.0\n",
        "    x_train[i, :,:] = np.array([np.array(l) for j in range(maxlen)])\n",
        "    \n",
        "x_train = x_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HFnm_ZkeZqgr",
        "colab_type": "code",
        "outputId": "57f72dbc-0b24-4f27-d470-a373f1e5aa68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1144, 200, 52)\n",
            "(1144, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4dotb0CKVdi7",
        "colab_type": "code",
        "outputId": "efc9cca3-7c29-465b-d7a3-496cd3f051b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(letters['a'][0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "veU81imyS3AL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model(batch_size=None):\n",
        "  source = Input(shape=(maxlen, 52), batch_size=batch_size, dtype=tf.float32, name='Input')\n",
        "  lstm = LSTM(3, name = 'LSTM', return_sequences=True)(source)\n",
        "  model = tf.keras.Model(inputs=[source], outputs=[lstm])\n",
        "  model.compile(\n",
        "      optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
        "      loss='mse',\n",
        "      metrics=['acc'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l4KfMBYzS8GK",
        "colab_type": "code",
        "outputId": "92526590-f986-4b09-9c6d-08ab883187f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "training_model = make_model(batch_size = 128)\n",
        "training_model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (128, 200, 52)            0         \n",
            "_________________________________________________________________\n",
            "LSTM (LSTM)                  (128, 200, 3)             672       \n",
            "=================================================================\n",
            "Total params: 672\n",
            "Trainable params: 672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P2Gg-grYS9PB",
        "colab_type": "code",
        "outputId": "e260e869-2164-447e-b471-c5884c16947e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    training_model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "tpu_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.1.60.218:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 8661455894642400886)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5216825019016262898)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3481956981224669402)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17932443353786491772)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17484260848487027136)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16757859653903774399)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14524504437808557622)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10445180731703216809)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17808877875521693179)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6225318586003221717)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2723959383075875977)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (128, 200, 52)            0         \n",
            "_________________________________________________________________\n",
            "LSTM (LSTM)                  (128, 200, 3)             672       \n",
            "=================================================================\n",
            "Total params: 672\n",
            "Trainable params: 672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfGmqPwTAr7",
        "colab_type": "code",
        "outputId": "119e14c1-eb15-49a8-e527-bc42e52d66d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1873
        },
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "history = tpu_model.fit(x_train, y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=128 * 8,\n",
        "                    validation_split=0.1)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "tpu_model.save_weights('./tpu_model.h5', overwrite=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1144 samples, validate on 115 samples\n",
            "Epoch 1/40\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 200, 52), dtype=tf.float32, name='Input_10'), TensorSpec(shape=(128, 200, 3), dtype=tf.float32, name='LSTM_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.029510974884033 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(15,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(15, 200, 52), dtype=tf.float32, name='Input_10'), TensorSpec(shape=(15, 200, 3), dtype=tf.float32, name='LSTM_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.375434637069702 secs\n",
            "1024/1144 [=========================>....] - ETA: 1s - loss: 52675.6602 - acc: 0.3669INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(14,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(14, 200, 52), dtype=tf.float32, name='Input_10'), TensorSpec(shape=(14, 200, 3), dtype=tf.float32, name='LSTM_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 5.22373628616333 secs\n",
            "1144/1144 [==============================] - 25s 22ms/sample - loss: 52922.5914 - acc: 0.3601 - val_loss: 57520.0391 - val_acc: 0.2048\n",
            "Epoch 2/40\n",
            "1144/1144 [==============================] - 0s 358us/sample - loss: 52916.8367 - acc: 0.2929 - val_loss: 57514.0742 - val_acc: 0.2094\n",
            "Epoch 3/40\n",
            "1144/1144 [==============================] - 0s 326us/sample - loss: 52911.7266 - acc: 0.2265 - val_loss: 57507.7070 - val_acc: 0.0879\n",
            "Epoch 4/40\n",
            "1144/1144 [==============================] - 0s 362us/sample - loss: 52905.8427 - acc: 0.1225 - val_loss: 57500.1523 - val_acc: 0.0840\n",
            "Epoch 5/40\n",
            "1144/1144 [==============================] - 0s 336us/sample - loss: 52898.7557 - acc: 0.0837 - val_loss: 57491.4297 - val_acc: 0.0825\n",
            "Epoch 6/40\n",
            "1144/1144 [==============================] - 0s 343us/sample - loss: 52890.2248 - acc: 0.0699 - val_loss: 57481.8008 - val_acc: 0.0820\n",
            "Epoch 7/40\n",
            "1144/1144 [==============================] - 0s 298us/sample - loss: 52881.1219 - acc: 0.0623 - val_loss: 57472.0273 - val_acc: 0.0820\n",
            "Epoch 8/40\n",
            "1144/1144 [==============================] - 0s 294us/sample - loss: 52871.9748 - acc: 0.0610 - val_loss: 57462.7031 - val_acc: 0.0820\n",
            "Epoch 9/40\n",
            "1144/1144 [==============================] - 0s 302us/sample - loss: 52863.0698 - acc: 0.0609 - val_loss: 57453.0547 - val_acc: 0.0830\n",
            "Epoch 10/40\n",
            "1144/1144 [==============================] - 0s 302us/sample - loss: 52854.1812 - acc: 0.0614 - val_loss: 57444.4336 - val_acc: 0.0830\n",
            "Epoch 11/40\n",
            "1144/1144 [==============================] - 0s 283us/sample - loss: 52845.9576 - acc: 0.0777 - val_loss: 57437.1875 - val_acc: 0.0853\n",
            "Epoch 12/40\n",
            "1144/1144 [==============================] - 0s 297us/sample - loss: 52839.0045 - acc: 0.0970 - val_loss: 57430.6914 - val_acc: 0.1304\n",
            "Epoch 13/40\n",
            "1144/1144 [==============================] - 0s 292us/sample - loss: 52832.7429 - acc: 0.1169 - val_loss: 57425.5430 - val_acc: 0.1343\n",
            "Epoch 14/40\n",
            "1144/1144 [==============================] - 0s 314us/sample - loss: 52827.8421 - acc: 0.1277 - val_loss: 57421.2500 - val_acc: 0.1345\n",
            "Epoch 15/40\n",
            "1144/1144 [==============================] - 0s 309us/sample - loss: 52823.6098 - acc: 0.1403 - val_loss: 57417.0898 - val_acc: 0.1481\n",
            "Epoch 16/40\n",
            "1144/1144 [==============================] - 0s 318us/sample - loss: 52819.5056 - acc: 0.1511 - val_loss: 57412.9492 - val_acc: 0.1508\n",
            "Epoch 17/40\n",
            "1144/1144 [==============================] - 0s 322us/sample - loss: 52815.5480 - acc: 0.1620 - val_loss: 57408.7070 - val_acc: 0.1528\n",
            "Epoch 18/40\n",
            "1144/1144 [==============================] - 0s 334us/sample - loss: 52811.5931 - acc: 0.1669 - val_loss: 57404.6836 - val_acc: 0.1538\n",
            "Epoch 19/40\n",
            "1144/1144 [==============================] - 0s 345us/sample - loss: 52807.7015 - acc: 0.1700 - val_loss: 57400.4609 - val_acc: 0.1540\n",
            "Epoch 20/40\n",
            "1144/1144 [==============================] - 0s 351us/sample - loss: 52803.6199 - acc: 0.1742 - val_loss: 57396.2812 - val_acc: 0.1536\n",
            "Epoch 21/40\n",
            "1144/1144 [==============================] - 0s 335us/sample - loss: 52799.5081 - acc: 0.1749 - val_loss: 57393.4492 - val_acc: 0.1546\n",
            "Epoch 22/40\n",
            "1144/1144 [==============================] - 0s 342us/sample - loss: 52796.2954 - acc: 0.1673 - val_loss: 57391.8398 - val_acc: 0.1547\n",
            "Epoch 23/40\n",
            "1144/1144 [==============================] - 0s 353us/sample - loss: 52794.1444 - acc: 0.1587 - val_loss: 57390.7461 - val_acc: 0.1472\n",
            "Epoch 24/40\n",
            "1144/1144 [==============================] - 0s 347us/sample - loss: 52792.6639 - acc: 0.1525 - val_loss: 57389.9766 - val_acc: 0.1103\n",
            "Epoch 25/40\n",
            "1144/1144 [==============================] - 0s 314us/sample - loss: 52791.6834 - acc: 0.1359 - val_loss: 57389.6094 - val_acc: 0.1107\n",
            "Epoch 26/40\n",
            "1144/1144 [==============================] - 0s 330us/sample - loss: 52791.1143 - acc: 0.1239 - val_loss: 57389.3203 - val_acc: 0.1124\n",
            "Epoch 27/40\n",
            "1144/1144 [==============================] - 0s 333us/sample - loss: 52790.6986 - acc: 0.1240 - val_loss: 57389.1992 - val_acc: 0.1249\n",
            "Epoch 28/40\n",
            "1144/1144 [==============================] - 0s 314us/sample - loss: 52790.4626 - acc: 0.1264 - val_loss: 57389.0859 - val_acc: 0.1243\n",
            "Epoch 29/40\n",
            "1144/1144 [==============================] - 0s 318us/sample - loss: 52790.2850 - acc: 0.1206 - val_loss: 57388.9883 - val_acc: 0.1248\n",
            "Epoch 30/40\n",
            "1144/1144 [==============================] - 0s 339us/sample - loss: 52790.1242 - acc: 0.1213 - val_loss: 57388.9141 - val_acc: 0.1262\n",
            "Epoch 31/40\n",
            "1144/1144 [==============================] - 0s 314us/sample - loss: 52790.0434 - acc: 0.1209 - val_loss: 57388.8438 - val_acc: 0.1292\n",
            "Epoch 32/40\n",
            "1144/1144 [==============================] - 0s 321us/sample - loss: 52789.9713 - acc: 0.1242 - val_loss: 57388.7656 - val_acc: 0.1291\n",
            "Epoch 33/40\n",
            "1144/1144 [==============================] - 0s 302us/sample - loss: 52789.8811 - acc: 0.1291 - val_loss: 57388.7031 - val_acc: 0.1297\n",
            "Epoch 34/40\n",
            "1144/1144 [==============================] - 0s 338us/sample - loss: 52789.8090 - acc: 0.1334 - val_loss: 57388.6328 - val_acc: 0.1378\n",
            "Epoch 35/40\n",
            "1144/1144 [==============================] - 0s 320us/sample - loss: 52789.7464 - acc: 0.1391 - val_loss: 57388.5703 - val_acc: 0.1436\n",
            "Epoch 36/40\n",
            "1144/1144 [==============================] - 0s 297us/sample - loss: 52789.6830 - acc: 0.1447 - val_loss: 57388.5078 - val_acc: 0.1483\n",
            "Epoch 37/40\n",
            "1144/1144 [==============================] - 0s 319us/sample - loss: 52789.6051 - acc: 0.1478 - val_loss: 57388.4453 - val_acc: 0.1528\n",
            "Epoch 38/40\n",
            "1144/1144 [==============================] - 0s 320us/sample - loss: 52789.5479 - acc: 0.1522 - val_loss: 57388.3867 - val_acc: 0.1553\n",
            "Epoch 39/40\n",
            "1144/1144 [==============================] - 0s 295us/sample - loss: 52789.4777 - acc: 0.1568 - val_loss: 57388.3242 - val_acc: 0.1574\n",
            "Epoch 40/40\n",
            "1144/1144 [==============================] - 0s 311us/sample - loss: 52789.4270 - acc: 0.1619 - val_loss: 57388.2734 - val_acc: 0.1597\n",
            "--- 40.2792284488678 seconds ---\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nqwHqx1VTDh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "06191d7d-91b9-41c1-96ee-dfcde15e5d8c"
      },
      "cell_type": "code",
      "source": [
        "inferencing_model = make_model(batch_size=None)\n",
        "inferencing_model.load_weights('./tpu_model.h5')\n",
        "inferencing_model.evaluate(x_test, y_test, batch_size=128 * 8)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2ea1a486a64f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minferencing_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minferencing_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tpu_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minferencing_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
          ]
        }
      ]
    }
  ]
}